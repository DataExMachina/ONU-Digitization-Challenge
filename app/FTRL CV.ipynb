{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from wordbatch.models import FTRL\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/dataframe/train.csv')\n",
    "test = pd.read_csv('../data/dataframe/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner_words(text):\n",
    "    \n",
    "    text = re.sub(r'[^a-zâàäçéèêëîïôùûüœ]+', ' ', text.lower())\n",
    "    return(text)\n",
    "\n",
    "def text_cleaner_chars(text):\n",
    "    \n",
    "    text = re.sub(r'[^a-zâàäçéèêëîïôùûüœ]+', '', text.lower())\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### english\n",
    "tf_en = TfidfVectorizer(ngram_range=(1,10), max_features=100000, preprocessor=text_cleaner_words)\n",
    "tf_en.fit(train[train.type == \"english\"].text.tolist())\n",
    "col_en = ['english_%s' % c for c in list(tf_en.vocabulary_)]\n",
    "\n",
    "### french\n",
    "tf_fr = TfidfVectorizer(ngram_range=(1,10), max_features=100000, preprocessor=text_cleaner_words)\n",
    "tf_fr.fit(train[train.type == \"french\"].text.tolist())\n",
    "col_fr = ['french_%s' % c for c in list(tf_fr.vocabulary_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chars extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### english\n",
    "tf_en_char = TfidfVectorizer(ngram_range=(1,1), max_features=100, preprocessor=text_cleaner_chars, analyzer='char')\n",
    "tf_en_char.fit(train[train.type == \"english\"].text.tolist())\n",
    "col_char_en = ['englishChar_%s' % c for c in list(tf_en_char.vocabulary_)]\n",
    "\n",
    "### french\n",
    "tf_fr_char = TfidfVectorizer(ngram_range=(1,1), max_features=100, preprocessor=text_cleaner_chars, analyzer='char')\n",
    "tf_fr_char.fit(train[train.type == \"french\"].text.tolist())\n",
    "col_char_fr = ['frenchChar_%s' % c for c in list(tf_fr_char.vocabulary_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = csr_matrix(\n",
    "    hstack(\n",
    "        [\n",
    "            tf_en.transform(train.text.tolist()),\n",
    "            tf_fr.transform(train.text.tolist()),\n",
    "            tf_en_char.transform(train.text.tolist()),\n",
    "            tf_fr_char.transform(train.text.tolist())\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "y = np.array([1 if x == 'english' else 0 for x in train.type.tolist()])\n",
    "\n",
    "columns = col_en + col_fr + col_char_en + col_char_fr \n",
    "\n",
    "Xtest = csr_matrix(\n",
    "    hstack(\n",
    "        [\n",
    "            tf_en.transform(test.text.tolist()),\n",
    "            tf_fr.transform(test.text.tolist()),\n",
    "            tf_en_char.transform(test.text.tolist()),\n",
    "            tf_fr_char.transform(test.text.tolist())\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4692, 200054)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8946236559139785\n",
      "0.9227722772277227\n",
      "0.9288537549407114\n",
      "0.9099099099099098\n",
      "0.9124999999999999\n",
      "0.9230769230769229\n",
      "0.9105691056910569\n",
      "0.9301310043668123\n",
      "0.924\n",
      "0.9170305676855894\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10, shuffle=True, random_state = 2701)\n",
    "\n",
    "scores = list()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    FTRLModel = FTRL(alpha=1.0, beta=1.0, L1=0.00001, L2=1.0, D=2 ** 25, iters=300)\n",
    "    FTRLModel.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(f1_score(y_test, np.round(FTRLModel.predict(X_test))))\n",
    "    print(scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(scores), np.std(scores) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "FTRLModel = FTRL(alpha=1.0, beta=1.0, L1=0.00001, L2=1.0, D=2 ** 25, iters=300)\n",
    "FTRLModel.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['en'] = FTRLModel.predict(Xtest)\n",
    "test['fr'] = 1 - test['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12133</th>\n",
       "      <td>8e62eb7ec323d3d2499422975752f378</td>\n",
       "      <td>Le port de Gdynia est sans doute susceptible d...</td>\n",
       "      <td>1.690486e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>719dfc6463ddc9f99ed97771cde35a4e</td>\n",
       "      <td>— 68 —\\n\\nune entente spéciale sur la base du ...</td>\n",
       "      <td>1.890985e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5854</th>\n",
       "      <td>d65d9fcc2adc4a75fd301021e5573e7b</td>\n",
       "      <td>= @ == ¢\\n\\n  \\n  \\n  \\n  \\n \\n \\n   \\n\\nAprés...</td>\n",
       "      <td>2.201007e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>6b7358314612f951faea67b3d0e67ee3</td>\n",
       "      <td>On cherche actuellement 4 savoir si ces trois ...</td>\n",
       "      <td>2.615427e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>67a96a786b14bddc843ca0b49fd490d0</td>\n",
       "      <td>— §7 —\\n\\nDans la Suéde méridionale, le codt t...</td>\n",
       "      <td>4.006107e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "12133  8e62eb7ec323d3d2499422975752f378   \n",
       "10302  719dfc6463ddc9f99ed97771cde35a4e   \n",
       "5854   d65d9fcc2adc4a75fd301021e5573e7b   \n",
       "3247   6b7358314612f951faea67b3d0e67ee3   \n",
       "1106   67a96a786b14bddc843ca0b49fd490d0   \n",
       "\n",
       "                                                    text            en   fr  \n",
       "12133  Le port de Gdynia est sans doute susceptible d...  1.690486e-07  1.0  \n",
       "10302  — 68 —\\n\\nune entente spéciale sur la base du ...  1.890985e-07  1.0  \n",
       "5854   = @ == ¢\\n\\n  \\n  \\n  \\n  \\n \\n \\n   \\n\\nAprés...  2.201007e-07  1.0  \n",
       "3247   On cherche actuellement 4 savoir si ces trois ...  2.615427e-07  1.0  \n",
       "1106   — §7 —\\n\\nDans la Suéde méridionale, le codt t...  4.006107e-07  1.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sort_values('fr', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataexmachina/DataProjects/CrowdAI/ONU_DigitalizationChallenge/crowdai-venv/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test = test[['id', 'en', 'fr']]\n",
    "test.columns = ['filename', 'en', 'fr']\n",
    "test['filename'] = list(map(lambda x: x+'.jpg', test.filename.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('../submit')\n",
    "except: None\n",
    "    \n",
    "test.to_csv('../submit/FTRL2609.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

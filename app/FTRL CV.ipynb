{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from wordbatch.models import FTRL\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/dataframe/train.csv')\n",
    "test = pd.read_csv('../data/dataframe/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner_words(text):\n",
    "    \n",
    "    text = re.sub(r'[^a-zâàäçéèêëîïôùûüœ]+', ' ', text.lower())\n",
    "    return(text)\n",
    "\n",
    "def text_cleaner_chars(text):\n",
    "    \n",
    "    text = re.sub(r'[^a-zâàäçéèêëîïôùûüœ]+', '', text.lower())\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### english\n",
    "tf_en = TfidfVectorizer(ngram_range=(1,10), max_features=100000, preprocessor=text_cleaner_words)\n",
    "tf_en.fit(train[train.type == \"english\"].text.tolist())\n",
    "col_en = ['english_%s' % c for c in list(tf_en.vocabulary_)]\n",
    "\n",
    "### french\n",
    "tf_fr = TfidfVectorizer(ngram_range=(1,10), max_features=100000, preprocessor=text_cleaner_words)\n",
    "tf_fr.fit(train[train.type == \"french\"].text.tolist())\n",
    "col_fr = ['french_%s' % c for c in list(tf_fr.vocabulary_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chars extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### english\n",
    "tf_en_char = TfidfVectorizer(ngram_range=(1,1), max_features=100, preprocessor=text_cleaner_chars, analyzer='char')\n",
    "tf_en_char.fit(train[train.type == \"english\"].text.tolist())\n",
    "col_char_en = ['englishChar_%s' % c for c in list(tf_en_char.vocabulary_)]\n",
    "\n",
    "### french\n",
    "tf_fr_char = TfidfVectorizer(ngram_range=(1,1), max_features=100, preprocessor=text_cleaner_chars, analyzer='char')\n",
    "tf_fr_char.fit(train[train.type == \"french\"].text.tolist())\n",
    "col_char_fr = ['frenchChar_%s' % c for c in list(tf_fr_char.vocabulary_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = csr_matrix(\n",
    "    hstack(\n",
    "        [\n",
    "            tf_en.transform(train.text.tolist()),\n",
    "            tf_fr.transform(train.text.tolist()),\n",
    "            tf_en_char.transform(train.text.tolist()),\n",
    "            tf_fr_char.transform(train.text.tolist())\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "y = np.array([1 if x == 'english' else 0 for x in train.type.tolist()])\n",
    "\n",
    "columns = col_en + col_fr + col_char_en + col_char_fr \n",
    "\n",
    "Xtest = csr_matrix(\n",
    "    hstack(\n",
    "        [\n",
    "            tf_en.transform(test.text.tolist()),\n",
    "            tf_fr.transform(test.text.tolist()),\n",
    "            tf_en_char.transform(test.text.tolist()),\n",
    "            tf_fr_char.transform(test.text.tolist())\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4692, 200054)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "835"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0.1, 50), (0.9041051025806782, 0.021980704003243645))\n",
      "((0.1, 100), (0.9101761932719276, 0.0265103319567878))\n",
      "((0.1, 300), (0.913895408201707, 0.02690711668741451))\n",
      "((0.1, 500), (0.9142595923259125, 0.02634780902059879))\n",
      "((0.5, 50), (0.8882956101254094, 0.02690646546475696))\n",
      "((0.5, 100), (0.9106506280914946, 0.02603339671154616))\n",
      "((0.5, 300), (0.916257959550849, 0.021863913712538274))\n",
      "((0.5, 500), (0.9192113985572045, 0.02061749818494385))\n",
      "((1, 50), (0.8547565810124615, 0.041680673778334024))\n",
      "((1, 100), (0.8978386113746085, 0.029610749742791237))\n",
      "((1, 300), (0.9173467198812704, 0.020430940279187848))\n",
      "((1, 500), (0.9189130972447362, 0.021549604851812502))\n",
      "((5, 50), (0.5290833842725421, 0.0800290068713067))\n",
      "((5, 100), (0.8339092567232852, 0.04678616765743912))\n",
      "((5, 300), (0.906687336980846, 0.025337822703594144))\n",
      "((5, 500), (0.915690466296572, 0.024358714726994874))\n",
      "((10, 50), (0.24395986795915553, 0.06475691095085098))\n",
      "((10, 100), (0.7444349808771321, 0.06217895932394041))\n",
      "((10, 300), (0.8925270056145571, 0.026800317725711068))\n",
      "((10, 500), (0.9100915540585162, 0.028213078865442758))\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10, shuffle=True, random_state = 2701)\n",
    "\n",
    "scores = list()\n",
    "for alpha in [0.1, 0.5, 1, 5, 10]:\n",
    "    for iters in [50, 100, 300, 500]:\n",
    "        tmp_scores = list()\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            FTRLModel = FTRL(alpha=alpha, beta=1.0, L1=0.00001, L2=1.0, D=2 ** 25, iters=iters)\n",
    "            FTRLModel.fit(X_train, y_train)\n",
    "    \n",
    "            tmp_scores.append(f1_score(y_test, np.round(FTRLModel.predict(X_test))))\n",
    "        scores.append(((alpha, iters), ((np.mean(tmp_scores), np.std(tmp_scores) * 2))))\n",
    "        print(scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "bestElem = pd.DataFrame(list(map(lambda x: list(chain.from_iterable(x)), scores))).sort_values(2, ascending = False).iloc[0,:2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "FTRLModel = FTRL(alpha=bestElem[0], beta=1.0, L1=0.00001, L2=1.0, D=2 ** 25, iters=bestElem[1])\n",
    "FTRLModel.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['en'] = FTRLModel.predict(Xtest)\n",
    "test['fr'] = 1 - test['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>719dfc6463ddc9f99ed97771cde35a4e</td>\n",
       "      <td>— 68 —\\n\\nune entente spéciale sur la base du ...</td>\n",
       "      <td>5.917678e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12133</th>\n",
       "      <td>8e62eb7ec323d3d2499422975752f378</td>\n",
       "      <td>Le port de Gdynia est sans doute susceptible d...</td>\n",
       "      <td>6.418887e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5854</th>\n",
       "      <td>d65d9fcc2adc4a75fd301021e5573e7b</td>\n",
       "      <td>= @ == ¢\\n\\n  \\n  \\n  \\n  \\n \\n \\n   \\n\\nAprés...</td>\n",
       "      <td>6.929701e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>6b7358314612f951faea67b3d0e67ee3</td>\n",
       "      <td>On cherche actuellement 4 savoir si ces trois ...</td>\n",
       "      <td>6.978659e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>3fb1775ea9ff5ac799e886f2a46f9a4f</td>\n",
       "      <td>\\n\\n \\n\\n \\n\\n \\n\\nSA ine\\n\\nM. Cavazzon1 (It...</td>\n",
       "      <td>9.436866e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "10302  719dfc6463ddc9f99ed97771cde35a4e   \n",
       "12133  8e62eb7ec323d3d2499422975752f378   \n",
       "5854   d65d9fcc2adc4a75fd301021e5573e7b   \n",
       "3247   6b7358314612f951faea67b3d0e67ee3   \n",
       "2554   3fb1775ea9ff5ac799e886f2a46f9a4f   \n",
       "\n",
       "                                                    text            en  \\\n",
       "10302  — 68 —\\n\\nune entente spéciale sur la base du ...  5.917678e-07   \n",
       "12133  Le port de Gdynia est sans doute susceptible d...  6.418887e-07   \n",
       "5854   = @ == ¢\\n\\n  \\n  \\n  \\n  \\n \\n \\n   \\n\\nAprés...  6.929701e-07   \n",
       "3247   On cherche actuellement 4 savoir si ces trois ...  6.978659e-07   \n",
       "2554    \\n\\n \\n\\n \\n\\n \\n\\nSA ine\\n\\nM. Cavazzon1 (It...  9.436866e-07   \n",
       "\n",
       "             fr  \n",
       "10302  0.999999  \n",
       "12133  0.999999  \n",
       "5854   0.999999  \n",
       "3247   0.999999  \n",
       "2554   0.999999  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sort_values('fr', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['id', 'en', 'fr']]\n",
    "test.columns = ['filename', 'en', 'fr']\n",
    "test['filename'] = list(map(lambda x: x+'.jpg', test.filename.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('../submit')\n",
    "except: None\n",
    "    \n",
    "test.to_csv('../submit/FTRL2709.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

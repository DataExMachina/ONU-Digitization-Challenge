{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold \n",
    "from wordbatch.models import FTRL\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/dataframe/train.csv')\n",
    "test = pd.read_csv('../data/dataframe/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'[^a-zâàäçéèêëîïôùûüœ]+', ' ', text.lower())\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub(r\"^\\s+\", \"\", text, flags=re.UNICODE)\n",
    "    text = re.sub(r\"\\s+$\", \"\", text, flags=re.UNICODE)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### english\n",
    "tf_en = TfidfVectorizer(ngram_range=(1,10), max_features=80000, preprocessor=text_cleaner, norm='l2', sublinear_tf=True)\n",
    "tf_en.fit(train[train.type == \"english\"].text.tolist())\n",
    "col_en = ['english_%s' % c for c in list(tf_en.vocabulary_)]\n",
    "\n",
    "### french\n",
    "tf_fr = TfidfVectorizer(ngram_range=(1,10), max_features=80000, preprocessor=text_cleaner, norm='l2', sublinear_tf=True)\n",
    "tf_fr.fit(train[train.type == \"french\"].text.tolist())\n",
    "col_fr = ['french_%s' % c for c in list(tf_fr.vocabulary_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### english\n",
    "tf_en_char = TfidfVectorizer(ngram_range=(1,1), max_features=100, preprocessor=text_cleaner, analyzer='char')\n",
    "tf_en_char.fit(train[train.type == \"english\"].text.tolist())\n",
    "col_char_en = ['englishChar_%s' % c for c in list(tf_en_char.vocabulary_)]\n",
    "\n",
    "### french\n",
    "tf_fr_char = TfidfVectorizer(ngram_range=(1,1), max_features=100, preprocessor=text_cleaner, analyzer='char')\n",
    "tf_fr_char.fit(train[train.type == \"french\"].text.tolist())\n",
    "col_char_fr = ['frenchChar_%s' % c for c in list(tf_fr_char.vocabulary_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = csr_matrix(\n",
    "    hstack(\n",
    "        [\n",
    "            tf_en.transform(train.text.tolist()),\n",
    "            tf_fr.transform(train.text.tolist()),\n",
    "            tf_en_char.transform(train.text.tolist()),\n",
    "            tf_fr_char.transform(train.text.tolist())\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "y = np.array([1 if x == 'english' else 0 for x in train.type.tolist()])\n",
    "\n",
    "columns = col_en + col_fr + col_char_en + col_char_fr #+ trainMetaText.columns.tolist()\n",
    "\n",
    "Xtest = csr_matrix(\n",
    "    hstack(\n",
    "        [\n",
    "            tf_en.transform(test.text.tolist()),\n",
    "            tf_fr.transform(test.text.tolist()),\n",
    "            tf_en_char.transform(test.text.tolist()),\n",
    "            tf_fr_char.transform(test.text.tolist())\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tf_en, tf_fr, tf_en_char, tf_fr_char; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FTRL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926530612244898\n",
      "0.9056603773584906\n",
      "0.9117043121149897\n",
      "0.9128630705394191\n",
      "0.9300411522633746\n",
      "0.918580375782881\n",
      "0.9090909090909092\n",
      "0.9224318658280922\n",
      "0.9221052631578948\n",
      "0.9110169491525425\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state = 2701)\n",
    "ftrlPred = list()\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    FTRLModel = FTRL(alpha=0.60,\n",
    "                     beta=1.0,\n",
    "                     L1=0.00001,\n",
    "                     L2=1.0,\n",
    "                     D=2 ** 25,\n",
    "                     iters=950)\n",
    "    FTRLModel.fit(X_train, y_train)\n",
    "\n",
    "    ftrlPred.append(FTRLModel.predict(Xtest))\n",
    "    validPred = FTRLModel.predict(X_test)\n",
    "    print(f1_score(y_test, np.round(validPred)))\n",
    "\n",
    "    del FTRLModel; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrlPredEnglish = pd.DataFrame(ftrlPred).T.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrlTest = test.copy()\n",
    "ftrlTest['en'] = ftrlPredEnglish\n",
    "ftrlTest['fr'] = 1 - ftrlTest['en']\n",
    "ftrlTest.drop(['text'], 1, inplace=True)\n",
    "ftrlTest = ftrlTest.rename(columns={'id':'filename'})\n",
    "ftrlTest['filename'] = [x+'.jpg' for x in ftrlTest['filename'].tolist()]\n",
    "ftrlTest.to_csv('../submit/FTRL.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9a03e71410809857e19dea363daee945.jpg</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8f0e95610aa9880767a04888fab11ebb.jpg</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.996488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d423882dfd1db8b145a1d2ce0663267d.jpg</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d52eebffd648db43a20d48c0921394db.jpg</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.999928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>318d0ddd145e53e496d0660dd6f0d2d3.jpg</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               filename        en        fr\n",
       "0  9a03e71410809857e19dea363daee945.jpg  0.999943  0.000057\n",
       "1  8f0e95610aa9880767a04888fab11ebb.jpg  0.003512  0.996488\n",
       "2  d423882dfd1db8b145a1d2ce0663267d.jpg  0.999985  0.000015\n",
       "3  d52eebffd648db43a20d48c0921394db.jpg  0.000072  0.999928\n",
       "4  318d0ddd145e53e496d0660dd6f0d2d3.jpg  0.999983  0.000017"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftrlTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
